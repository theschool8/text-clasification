{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News Title Classification.ipynb",
      "provenance": [],
      "mount_file_id": "1l3xD1qYF3n_8dCuSK54NEi8vb837v0mS",
      "authorship_tag": "ABX9TyOO64Vby0AUF5I/3BUa9Xmz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/theschool8/text-clasification/blob/main/News_Title_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBfKZpRcgX8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e405c0c8-92ff-4993-f5a3-bb28b1f6655a"
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgcGTf1ShkGT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "005074d4-2b38-4c57-94a4-ed77a67981aa"
      },
      "source": [
        "data = pd.read_excel('/content/drive/My Drive/Bagidata/News Title.xls', usecols=[1,2])\n",
        "data.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>News Title</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Google+ rolls out 'Stories' for tricked out ph...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dov Charney's Redeeming Quality</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>White God adds Un Certain Regard to the Palm Dog</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Google shows off Androids for wearables, cars,...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>China May new bank loans at 870.8 bln yuan</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Firefox Windows 8 Metro Browser Development Ca...</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Destiny Beta Kicks Off In July</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Apple &amp; Google's Motorola end legal battle</td>\n",
              "      <td>Technology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>UPDATE 2-Facebook Q1 revenue grows 72 percent ...</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Selena Gomez, Justin Bieber Spotted at the Sam...</td>\n",
              "      <td>Entertainment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          News Title       Category\n",
              "0  Google+ rolls out 'Stories' for tricked out ph...     Technology\n",
              "1                    Dov Charney's Redeeming Quality       Business\n",
              "2   White God adds Un Certain Regard to the Palm Dog  Entertainment\n",
              "3  Google shows off Androids for wearables, cars,...     Technology\n",
              "4         China May new bank loans at 870.8 bln yuan       Business\n",
              "5  Firefox Windows 8 Metro Browser Development Ca...     Technology\n",
              "6                     Destiny Beta Kicks Off In July     Technology\n",
              "7         Apple & Google's Motorola end legal battle     Technology\n",
              "8  UPDATE 2-Facebook Q1 revenue grows 72 percent ...       Business\n",
              "9  Selena Gomez, Justin Bieber Spotted at the Sam...  Entertainment"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-AH6CaDi5Vw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "80859321-7a2e-4bfc-bdd1-d1e04a071eb9"
      },
      "source": [
        "sns.countplot('Category', data=data)\n",
        "plt.xlabel('Category')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Category')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-MT_hjZkaAL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "73bba31f-0062-456f-c3c5-36742e74aa46"
      },
      "source": [
        "category_index = pd.factorize(data['Category'])[1]\n",
        "print(category_index)\n",
        "category_num = pd.factorize(data['Category'])[0]\n",
        "category_num"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Technology', 'Business', 'Entertainment', 'Medical'], dtype='object')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 2, 2, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l97ks35UFCn1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "874d165d-e356-4830-d3f1-a7de4e989116"
      },
      "source": [
        "title = data['News Title']\n",
        "title[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Google+ rolls out 'Stories' for tricked out ph...\n",
              "1                      Dov Charney's Redeeming Quality\n",
              "2     White God adds Un Certain Regard to the Palm Dog\n",
              "3    Google shows off Androids for wearables, cars,...\n",
              "4           China May new bank loans at 870.8 bln yuan\n",
              "5    Firefox Windows 8 Metro Browser Development Ca...\n",
              "6                       Destiny Beta Kicks Off In July\n",
              "7           Apple & Google's Motorola end legal battle\n",
              "8    UPDATE 2-Facebook Q1 revenue grows 72 percent ...\n",
              "9    Selena Gomez, Justin Bieber Spotted at the Sam...\n",
              "Name: News Title, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlGvLa4_luzg"
      },
      "source": [
        "def PreProcess(list):\n",
        "  post_data = []\n",
        "  stemmer= PorterStemmer()\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "  for line in list:\n",
        "    # Case folding\n",
        "    data = str(line).lower()\n",
        "    # remove number \n",
        "    data = re.sub(r'\\d+', '', data)\n",
        "    # remove punctuation\n",
        "    data = data.translate(str.maketrans({a:None for a in string.punctuation}))\n",
        "    # remove double, triple, and so on space\n",
        "    data = re.sub('\\s+',' ', data)\n",
        "    tokens = word_tokenize(data)\n",
        "    stemmer_sentence = []\n",
        "    for word in tokens:\n",
        "      # remove stopwords\n",
        "      if word not in stop_words :\n",
        "      #lemmatization\n",
        "        stemmer_word = stemmer.stem(word)\n",
        "        stemmer_sentence.append(stemmer_word)\n",
        "    data = ' '.join(stemmer_sentence)\n",
        "    # append all \n",
        "    post_data.append(data)\n",
        "  return post_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EvKykjxN_tp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9cbea568-1df1-4263-d3ab-4ed03b7f15b6"
      },
      "source": [
        "post_title = PreProcess(title)\n",
        "post_title[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['googl roll stori trick photo playback',\n",
              " 'dov charney redeem qualiti',\n",
              " 'white god add un certain regard palm dog',\n",
              " 'googl show android wearabl car tv',\n",
              " 'china may new bank loan bln yuan',\n",
              " 'firefox window metro browser develop cancel mozilla',\n",
              " 'destini beta kick juli',\n",
              " 'appl googl motorola end legal battl',\n",
              " 'updat facebook q revenu grow percent rise mobil ad',\n",
              " 'selena gomez justin bieber spot record studio miami']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BnBLGx0OmGI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "eb7f94d9-71fb-42d7-dca1-ab4c2e9f84ca"
      },
      "source": [
        "tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=10, max_features=3000)\n",
        "X_tf = tfidf.fit_transform(post_title)\n",
        "tf = pd.DataFrame(X_tf.toarray(), columns=tfidf.get_feature_names())\n",
        "tf"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aaa</th>\n",
              "      <th>aaliyah</th>\n",
              "      <th>aapl</th>\n",
              "      <th>abandon</th>\n",
              "      <th>abbvi</th>\n",
              "      <th>abc</th>\n",
              "      <th>abort</th>\n",
              "      <th>abus</th>\n",
              "      <th>acceler</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accid</th>\n",
              "      <th>accord</th>\n",
              "      <th>account</th>\n",
              "      <th>accus</th>\n",
              "      <th>ackman</th>\n",
              "      <th>acquir</th>\n",
              "      <th>acquisit</th>\n",
              "      <th>across</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>activ</th>\n",
              "      <th>activist</th>\n",
              "      <th>actor</th>\n",
              "      <th>actress</th>\n",
              "      <th>actual</th>\n",
              "      <th>ad</th>\n",
              "      <th>adam</th>\n",
              "      <th>adapt</th>\n",
              "      <th>add</th>\n",
              "      <th>addit</th>\n",
              "      <th>address</th>\n",
              "      <th>administr</th>\n",
              "      <th>admit</th>\n",
              "      <th>adob</th>\n",
              "      <th>adopt</th>\n",
              "      <th>adult</th>\n",
              "      <th>advanc</th>\n",
              "      <th>advertis</th>\n",
              "      <th>advic</th>\n",
              "      <th>...</th>\n",
              "      <th>wors</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>would</th>\n",
              "      <th>wow</th>\n",
              "      <th>write</th>\n",
              "      <th>writer</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wutang</th>\n",
              "      <th>wwdc</th>\n",
              "      <th>wwe</th>\n",
              "      <th>xbox</th>\n",
              "      <th>xbox one</th>\n",
              "      <th>xmen</th>\n",
              "      <th>xmen day</th>\n",
              "      <th>xmen director</th>\n",
              "      <th>xp</th>\n",
              "      <th>xperia</th>\n",
              "      <th>yahoo</th>\n",
              "      <th>ye</th>\n",
              "      <th>year</th>\n",
              "      <th>year ago</th>\n",
              "      <th>yearold</th>\n",
              "      <th>yellen</th>\n",
              "      <th>yen</th>\n",
              "      <th>yet</th>\n",
              "      <th>yield</th>\n",
              "      <th>york</th>\n",
              "      <th>youll</th>\n",
              "      <th>young</th>\n",
              "      <th>your</th>\n",
              "      <th>youtub</th>\n",
              "      <th>yuan</th>\n",
              "      <th>zac</th>\n",
              "      <th>zac efron</th>\n",
              "      <th>zendaya</th>\n",
              "      <th>zillow</th>\n",
              "      <th>zone</th>\n",
              "      <th>zoom</th>\n",
              "      <th>zuckerberg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368501</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.495935</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65530</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.329633</td>\n",
              "      <td>0.343891</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65531</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65532</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65533</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65534</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>65535 rows  3000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       aaa  aaliyah  aapl  abandon  ...  zillow  zone  zoom  zuckerberg\n",
              "0      0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "1      0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "2      0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "3      0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "4      0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "...    ...      ...   ...      ...  ...     ...   ...   ...         ...\n",
              "65530  0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "65531  0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "65532  0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "65533  0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "65534  0.0      0.0   0.0      0.0  ...     0.0   0.0   0.0         0.0\n",
              "\n",
              "[65535 rows x 3000 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kqv8TQeBfMo"
      },
      "source": [
        "# Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp-yEeSNfyxL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "ba51c9b2-e733-4298-acf4-dc2f556fbd0f"
      },
      "source": [
        "%%time \n",
        "X_train, X_test, y_train, y_test = train_test_split(tf, category_num, \n",
        "                                                    test_size = 0.3, \n",
        "                                                    random_state = 60)\n",
        "\n",
        "# Train our model\n",
        "nbc = MultinomialNB()\n",
        "nbc.fit(X_train, y_train)\n",
        "yhat_nbc = nbc.predict(X_test)\n",
        "print(\"Training: \\n\", classification_report(y_train, nbc.predict(X_train)))\n",
        "print(\"Testing: \\n\", classification_report(y_test, yhat_nbc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.85      0.85     11729\n",
            "           1       0.85      0.87      0.86     12484\n",
            "           2       0.92      0.95      0.93     16716\n",
            "           3       0.92      0.78      0.84      4945\n",
            "\n",
            "    accuracy                           0.89     45874\n",
            "   macro avg       0.89      0.86      0.87     45874\n",
            "weighted avg       0.89      0.89      0.88     45874\n",
            "\n",
            "Testing: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84      5047\n",
            "           1       0.83      0.86      0.85      5223\n",
            "           2       0.91      0.94      0.93      7245\n",
            "           3       0.90      0.75      0.82      2146\n",
            "\n",
            "    accuracy                           0.87     19661\n",
            "   macro avg       0.87      0.85      0.86     19661\n",
            "weighted avg       0.87      0.87      0.87     19661\n",
            "\n",
            "CPU times: user 2.2 s, sys: 1.24 s, total: 3.44 s\n",
            "Wall time: 2.36 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEuS0YJ827qG"
      },
      "source": [
        "def kfold_cv(n_kfold, X, y, model):\n",
        "  cv = StratifiedKFold(n_splits=n_kfold, shuffle=False)\n",
        "  i=1\n",
        "  for train_idx, test_idx in cv.split(X, y):\n",
        "    X_train, y_train = X[train_idx], y[train_idx]\n",
        "    X_test, y_test = X[test_idx], y[test_idx]\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy_train = accuracy_score(y_train, model.predict(X_train))\n",
        "    yhat = model.predict(X_test)\n",
        "    accuracy_test = accuracy_score(y_test, yhat)\n",
        "    f1 = f1_score(y_test, yhat, average='weighted')\n",
        "    clt_test = pd.crosstab(yhat, y_test,  rownames=['Predicted'], \n",
        "                  colnames=['Actual'], margins=True)\n",
        "\n",
        "    print (\"------------------FOLD KE = {:.0f}-------------------\".format(i))\n",
        "    i=i+1\n",
        "    print (\"Accuracy Training = {:.4f}\".format(accuracy_train))\n",
        "    print (\"Accuracy Testing = {:.4f}\".format(accuracy_test))\n",
        "    print (\"F1 Score = {:.4f}\".format(f1))\n",
        "    print(\"Confusion Matrix: \\n\", clt_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k09cFywIWAlt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec27a533-2d98-4d54-c6cb-4930b182861d"
      },
      "source": [
        "%%time\n",
        "nbc = MultinomialNB()\n",
        "kfold_cv(5, tf.values, category_num, nbc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------FOLD KE = 1-------------------\n",
            "Accuracy Training = 0.8835\n",
            "Accuracy Testing = 0.8771\n",
            "F1 Score = 0.8763\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2843   301   143    71   3358\n",
            "1           314  3054    81   142   3591\n",
            "2           164   140  4532   138   4974\n",
            "3            35    46    36  1067   1184\n",
            "All        3356  3541  4792  1418  13107\n",
            "------------------FOLD KE = 2-------------------\n",
            "Accuracy Training = 0.8841\n",
            "Accuracy Testing = 0.8758\n",
            "F1 Score = 0.8752\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2840   304   129    87   3360\n",
            "1           333  3050   110   124   3617\n",
            "2           143   135  4511   129   4918\n",
            "3            39    53    42  1078   1212\n",
            "All        3355  3542  4792  1418  13107\n",
            "------------------FOLD KE = 3-------------------\n",
            "Accuracy Training = 0.8844\n",
            "Accuracy Testing = 0.8750\n",
            "F1 Score = 0.8746\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2827   323   147    76   3373\n",
            "1           344  3051   123   124   3642\n",
            "2           144   119  4495   123   4881\n",
            "3            40    49    27  1095   1211\n",
            "All        3355  3542  4792  1418  13107\n",
            "------------------FOLD KE = 4-------------------\n",
            "Accuracy Training = 0.8843\n",
            "Accuracy Testing = 0.8720\n",
            "F1 Score = 0.8713\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2826   307   151    70   3354\n",
            "1           330  3046   116   155   3647\n",
            "2           165   155  4493   129   4942\n",
            "3            34    33    33  1064   1164\n",
            "All        3355  3541  4793  1418  13107\n",
            "------------------FOLD KE = 5-------------------\n",
            "Accuracy Training = 0.8853\n",
            "Accuracy Testing = 0.8730\n",
            "F1 Score = 0.8725\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2803   319   131    63   3316\n",
            "1           344  3040   116   144   3644\n",
            "2           182   142  4509   121   4954\n",
            "3            26    40    36  1091   1193\n",
            "All        3355  3541  4792  1419  13107\n",
            "CPU times: user 11.2 s, sys: 2.28 s, total: 13.4 s\n",
            "Wall time: 8.61 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pieh8aqmBqHR"
      },
      "source": [
        "# Logistic Regression (One vs Rest)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzDK8vJyahDo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "af8daf34-b792-43e7-c4f5-9a33197b683d"
      },
      "source": [
        "%%time\n",
        "X_train, X_test, y_train, y_test = train_test_split(tf, category_num, \n",
        "                                                    test_size = 0.2, \n",
        "                                                    random_state = 60)\n",
        "\n",
        "# Instantiate the classifier\n",
        "logreg = OneVsRestClassifier(LogisticRegression())\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "logreg.fit(X_train, y_train)\n",
        "y_hat = logreg.predict(X_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Training: \\n\", classification_report(y_train, logreg.predict(X_train)))\n",
        "print(\"Testing Regression: \\n\", classification_report(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.87      0.88     11729\n",
            "           1       0.88      0.89      0.88     12484\n",
            "           2       0.92      0.97      0.94     16716\n",
            "           3       0.93      0.81      0.86      4945\n",
            "\n",
            "    accuracy                           0.90     45874\n",
            "   macro avg       0.91      0.88      0.89     45874\n",
            "weighted avg       0.90      0.90      0.90     45874\n",
            "\n",
            "Testing Regression: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.85      0.87      5047\n",
            "           1       0.85      0.87      0.86      5223\n",
            "           2       0.91      0.96      0.93      7245\n",
            "           3       0.90      0.78      0.84      2146\n",
            "\n",
            "    accuracy                           0.89     19661\n",
            "   macro avg       0.89      0.86      0.87     19661\n",
            "weighted avg       0.89      0.89      0.89     19661\n",
            "\n",
            "CPU times: user 2min 20s, sys: 4.65 s, total: 2min 25s\n",
            "Wall time: 1min 14s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "td38rJ9h-cv1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "71dbda09-9d37-46a7-f2dd-bf33ad0827d4"
      },
      "source": [
        "%%time\n",
        "logreg = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
        "kfold_cv(5, tf.values, category_num, logreg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------FOLD KE = 1-------------------\n",
            "Accuracy Training = 0.9048\n",
            "Accuracy Testing = 0.8909\n",
            "F1 Score = 0.8899\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2872   245    65    56   3238\n",
            "1           256  3084    77   130   3547\n",
            "2           190   158  4623   134   5105\n",
            "3            38    54    27  1098   1217\n",
            "All        3356  3541  4792  1418  13107\n",
            "------------------FOLD KE = 2-------------------\n",
            "Accuracy Training = 0.9050\n",
            "Accuracy Testing = 0.8894\n",
            "F1 Score = 0.8886\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2865   261    73    59   3258\n",
            "1           294  3075    89   119   3577\n",
            "2           165   149  4596   119   5029\n",
            "3            31    57    34  1121   1243\n",
            "All        3355  3542  4792  1418  13107\n",
            "------------------FOLD KE = 3-------------------\n",
            "Accuracy Training = 0.9051\n",
            "Accuracy Testing = 0.8859\n",
            "F1 Score = 0.8851\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2853   284    71    64   3272\n",
            "1           295  3070   124   120   3609\n",
            "2           172   136  4575   121   5004\n",
            "3            35    52    22  1113   1222\n",
            "All        3355  3542  4792  1418  13107\n",
            "------------------FOLD KE = 4-------------------\n",
            "Accuracy Training = 0.9052\n",
            "Accuracy Testing = 0.8857\n",
            "F1 Score = 0.8848\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2874   277    72    52   3275\n",
            "1           269  3065   107   144   3585\n",
            "2           187   162  4581   133   5063\n",
            "3            25    37    33  1089   1184\n",
            "All        3355  3541  4793  1418  13107\n",
            "------------------FOLD KE = 5-------------------\n",
            "Accuracy Training = 0.9051\n",
            "Accuracy Testing = 0.8862\n",
            "F1 Score = 0.8855\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2827   262    65    44   3198\n",
            "1           304  3075   106   136   3621\n",
            "2           192   161  4585   110   5048\n",
            "3            32    43    36  1129   1240\n",
            "All        3355  3541  4792  1419  13107\n",
            "CPU times: user 12min 55s, sys: 23.3 s, total: 13min 18s\n",
            "Wall time: 6min 48s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP5tdfI1D8Wq"
      },
      "source": [
        "# SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n92dBc3YCXrB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "e5aa3eeb-0e55-4e71-ff91-f957e9586cf6"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(tf, category_num, \n",
        "                                                    test_size = 0.2, \n",
        "                                                    random_state = 60)\n",
        "svc = LinearSVC()\n",
        "svc.fit(X_train, y_train)\n",
        "y_hat = svc.predict(X_test)\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Training: \\n\", classification_report(y_train, svc.predict(X_train)))\n",
        "print(\"Testing: \\n\", classification_report(y_test, y_hat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.90     13477\n",
            "           1       0.89      0.90      0.89     14180\n",
            "           2       0.95      0.97      0.96     19110\n",
            "           3       0.92      0.87      0.89      5661\n",
            "\n",
            "    accuracy                           0.92     52428\n",
            "   macro avg       0.92      0.91      0.91     52428\n",
            "weighted avg       0.92      0.92      0.92     52428\n",
            "\n",
            "Testing: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.86      0.87      3299\n",
            "           1       0.86      0.87      0.87      3527\n",
            "           2       0.93      0.95      0.94      4851\n",
            "           3       0.88      0.82      0.85      1430\n",
            "\n",
            "    accuracy                           0.89     13107\n",
            "   macro avg       0.89      0.88      0.88     13107\n",
            "weighted avg       0.89      0.89      0.89     13107\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n2bRYL4DMge",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "70c649e5-361d-4086-c46f-add689cf5009"
      },
      "source": [
        "%%time\n",
        "svc = LinearSVC()\n",
        "kfold_cv(5, tf.values, category_num, svc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------FOLD KE = 1-------------------\n",
            "Accuracy Training = 0.9189\n",
            "Accuracy Testing = 0.8947\n",
            "F1 Score = 0.8943\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2910   267    82    51   3310\n",
            "1           261  3080    89   119   3549\n",
            "2           142   127  4576    87   4932\n",
            "3            43    67    45  1161   1316\n",
            "All        3356  3541  4792  1418  13107\n",
            "------------------FOLD KE = 2-------------------\n",
            "Accuracy Training = 0.9190\n",
            "Accuracy Testing = 0.8945\n",
            "F1 Score = 0.8942\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2905   271    84    61   3321\n",
            "1           279  3082   102   106   3569\n",
            "2           122   117  4558    72   4869\n",
            "3            49    72    48  1179   1348\n",
            "All        3355  3542  4792  1418  13107\n",
            "------------------FOLD KE = 3-------------------\n",
            "Accuracy Training = 0.9197\n",
            "Accuracy Testing = 0.8907\n",
            "F1 Score = 0.8905\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2888   290    89    53   3320\n",
            "1           279  3072   131   110   3592\n",
            "2           142   112  4534    74   4862\n",
            "3            46    68    38  1181   1333\n",
            "All        3355  3542  4792  1418  13107\n",
            "------------------FOLD KE = 4-------------------\n",
            "Accuracy Training = 0.9188\n",
            "Accuracy Testing = 0.8923\n",
            "F1 Score = 0.8919\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2906   275    82    50   3313\n",
            "1           264  3081   110   123   3578\n",
            "2           143   134  4554    90   4921\n",
            "3            42    51    47  1155   1295\n",
            "All        3355  3541  4793  1418  13107\n",
            "------------------FOLD KE = 5-------------------\n",
            "Accuracy Training = 0.9193\n",
            "Accuracy Testing = 0.8909\n",
            "F1 Score = 0.8906\n",
            "Confusion Matrix: \n",
            " Actual        0     1     2     3    All\n",
            "Predicted                               \n",
            "0          2869   271    76    36   3252\n",
            "1           297  3076   110   124   3607\n",
            "2           146   133  4546    73   4898\n",
            "3            43    61    60  1186   1350\n",
            "All        3355  3541  4792  1419  13107\n",
            "CPU times: user 15.1 s, sys: 708 ms, total: 15.8 s\n",
            "Wall time: 13.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}